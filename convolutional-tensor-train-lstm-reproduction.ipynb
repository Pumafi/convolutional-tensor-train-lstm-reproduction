{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, AvgPool2D, Layer, Add\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "\n",
    "path_moving_mnist = \"./data/mnist_test_seq.npy\"\n",
    "assert os.path.exists(path_moving_mnist), \"ASSERT ERROR: The file does not exist.\"\n",
    "data = np.float32(np.load(path_moving_mnist) / 255.0)\n",
    "data_samples = data.shape[0]\n",
    "\n",
    "data_frames  = data.shape[1]\n",
    "data = np.swapaxes(data, 0, 1)\n",
    "data = np.expand_dims(data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 20, 64, 64, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_samples, data_frames)\n",
    "display(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTTLSTMLayer(Layer):\n",
    "    def __init__(self, input_channels, hidden_channels,\n",
    "                      order=3, steps=3, ranks=8,\n",
    "                      kernel_size=(5, 5), bias=True):\n",
    "        super(ConvTTLSTMLayer, self).__init__()\n",
    "        \n",
    "        ## Input/output interfaces\n",
    "        self.input_channels  = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        \n",
    "        # Number of hidden states taken\n",
    "        self.steps = steps\n",
    "        # Number of G matrices\n",
    "        self.order = order\n",
    "        # How many hiddent step by group to be preprocessed together\n",
    "        self.lags = steps - order + 1\n",
    "        \n",
    "        ## Convolutional operations\n",
    "        padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        \n",
    "        # Change to 3D ? Same effecct but different optimisations\n",
    "        preprocessing_Conv2D = lambda out_channels:  Conv2D(out_channels,\n",
    "                                                            kernel_size=kernel_size,\n",
    "                                                            padding=padding + (0,),\n",
    "                                                            use_bias=bias)\n",
    "    \n",
    "        tt_Conv2D = lambda out_channels:  Conv2D(out_channels,\n",
    "                                                  kernel_size=kernel_size,\n",
    "                                                  padding=padding,\n",
    "                                                  use_bias=bias)\n",
    "\n",
    "        self.layers_preprocess = []\n",
    "        self.layers_conv2d = []\n",
    "        \n",
    "        for l in range(order):\n",
    "            self.layers_preprocess.append(preprocessing_Conv2D( \n",
    "                out_channels = ranks if l < order - 1 else 4 * hidden_channels))\n",
    "            \n",
    "            self.layers_conv2d.append(tt_Conv2D(out_channels = ranks))\n",
    "        \n",
    "        def initialize(self, inputs):\n",
    "            '''\n",
    "            Initialize the hidden cell states H\n",
    "            '''\n",
    "            \n",
    "            batch_size, input_channels, height, width = inputs.size()\n",
    "            \n",
    "            self.hidden_states = [tf.zeros([batch_size, \n",
    "                height, width, self.hidden_channels])] * self.steps\n",
    "            self.hidden_state_index = 0\n",
    "            self.cell_states = tf.zeros([batch_size,\n",
    "                height, width, self.hidden_channels])\n",
    "        \n",
    "        def call(self, inputs, first_step = False):\n",
    "            '''\n",
    "            Call the model\n",
    "            '''\n",
    "            if first_step:\n",
    "                self.initialize(inputs)\n",
    "                first_step = False\n",
    "            \n",
    "            ## Preprocessing + Convolutional tensor-train module\n",
    "            ## Algorithm 2\n",
    "            for i in range(self.order):\n",
    "                input_pointer = self.hidden_state_index if not i else (input_pointer + 1) % self.steps\n",
    "                \n",
    "                # Start hidden states input at pointer but wrap around\n",
    "                input_states = self.hidden_states[input_pointer:] + self.hidden_states[:input_pointer]\n",
    "                \n",
    "                # Take one group of Hidden States\n",
    "                input_states = input_states[:self.lags]\n",
    "                \n",
    "                input_states = tf.stack(input_states, dim=-1)\n",
    "                input_states = self.layers_preprocess[l](input_states)\n",
    "                \n",
    "                if i == 0:\n",
    "                    temp_states = input_states\n",
    "                else: # if i > 0\n",
    "                    temp_states = input_states + self.layers_conv2d[l - 1](temp_states)\n",
    "                \n",
    "            ## Standard convolutional-LSTM module\n",
    "            concat_conv = self.layers_conv2d(tf.concat([inputs, temps_states], dim=-1))\n",
    "            cc_i, cc_f, cc_o, cc_g = tf.split(concat_conv, self.hidden_channels, dim = -1)\n",
    "            \n",
    "            \n",
    "            i = tf.math.sigmoid(cc_i)\n",
    "            f = tf.math.sigmoid(cc_f)\n",
    "            o = tf.math.sigmoid(cc_o)\n",
    "            g = tf.math.tanh(cc_g)\n",
    "            \n",
    "            self.cell_states = f * self.cell_states + i * g\n",
    "            outputs = o * torch.tanh(self.cell_states)\n",
    "            self.hidden_states[self.hidden_state_index] = outputs\n",
    "            self.hidden_pointer = (self.hidden_state_index + 1) % self.steps\n",
    "\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "convttlstm = ConvTTLSTMLayer(5,3)\n",
    "convttlstm.build((None, *input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTTLSTMNet(Model):\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 layers_per_block:list, hidden_channels:list, skip_stride = None,\n",
    "                 # Params for the TTLSTM\n",
    "                 order=3, steps=3, ranks=8,\n",
    "                 kernel_size = (3,3), bias = True,\n",
    "                 output_sigmoid = False):\n",
    "        super(ConvTTLSTMNet, self).__init__()\n",
    "        \n",
    "        ## Hyperparameters\n",
    "        self.layers_per_block = layers_per_block\n",
    "        self.hidden_channels  = hidden_channels\n",
    "\n",
    "        self.num_blocks = len(layers_per_block)\n",
    "        assert self.num_blocks == len(hidden_channels), \"Invalid number of blocks.\"\n",
    "        \n",
    "        \n",
    "        self.skip_stride = (self.num_blocks + 1) if skip_stride is None else skip_stride\n",
    "\n",
    "        self.output_sigmoid = output_sigmoid\n",
    "        \n",
    "        self.layers_ = {}\n",
    "        \n",
    "        # Model Architecture\n",
    "        for b in range(self.num_blocks):\n",
    "            for l in range(layers_per_block[b]):\n",
    "                # number of input channels to the current layer\n",
    "                if l > 0:\n",
    "                    channels = hidden_channels[b]\n",
    "                elif b == 0:\n",
    "                    channels = input_channels\n",
    "                else:\n",
    "                    # First layer of a block after the first one\n",
    "                    channels = hidden_channels[b - 1]\n",
    "                \n",
    "                # We keep the layer id for skip connections\n",
    "                # FIXME ? Maybe there's something to do that with Keras ? Unsure\n",
    "                lid = \"b{}l{}\".format(b, l)\n",
    "                \n",
    "                cttlstmlayer = ConvTTLSTMLayer(\n",
    "                    input_channels = channels, hidden_channels = hidden_channels[b],\n",
    "                    order = order, steps = steps, ranks = ranks, \n",
    "                    kernel_size = kernel_size, bias = bias)\n",
    "                \n",
    "                self.layers_[lid] = cttlstmlayer\n",
    "                \n",
    "        # Last Layer\n",
    "        # nb of input\n",
    "        channels = hidden_channels[-1]\n",
    "        \n",
    "        # ???????\n",
    "        # Si il y a plus de blocks que la distance de skip, alots on ajoute Ã  l'input\n",
    "        # le skip ? FIXME ==> Essayez de comprendre\n",
    "        if self.num_blocks >= self.skip_stride:\n",
    "            channels += hidden_channels[-1-self.skip_stride]\n",
    "            \n",
    "        if self.output_sigmoid:\n",
    "            activation=\"sigmoid\"\n",
    "        else:\n",
    "            activation=None\n",
    "            \n",
    "        self.layers_[\"output\"] = Conv2D(input_channels, kernel_size=(1,1), \n",
    "                                       activation=activation, padding=\"same\", use_bias=True)\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, input_frames:int, future_frames:int, output_frames:int,\n",
    "                teacher_forcing = False, scheduled_sampling_ratio = 0):\n",
    "            # tf is teacher forcing ?\n",
    "        if teacher_forcing and scheduled_sampling_ratio > 1e-6:\n",
    "            teacher_forcing_mask = np.random.binomial(size=(inputs.size(0), future_frames - 1, 1, 1, 1), n=1, p=scheduled_sampling_ratio)\n",
    "        else:\n",
    "            teacher_forcing = False\n",
    "            \n",
    "        total_steps = input_frames + future_frames - 1\n",
    "        outputs = [None] * total_steps\n",
    "\n",
    "        for t in range(total_steps):\n",
    "            if t < input_frames: \n",
    "                input_ = inputs[:, t]\n",
    "            elif not teacher_forcing:\n",
    "                input_ = outputs[t-1]\n",
    "            else: # if t >= input_frames and teacher_forcing:\n",
    "                mask = teacher_forcing_mask[:, t - input_frames]\n",
    "                input_ = inputs[:, t] * mask + outputs[t-1] * (1 - mask)\n",
    "\n",
    "            print(input_.shape)\n",
    "            first_step = (t == 0)\n",
    "\n",
    "            queue = []\n",
    "\n",
    "            for b in range(self.num_blocks):\n",
    "                for l in range(self.layers_per_block[b]):\n",
    "                    lid = \"b{}l{}\".format(b, l)\n",
    "                    input_ = self.layers_[lid](input_, first_step = first_step)\n",
    "\n",
    "                queue.append(input_)\n",
    "                if b >= self.skip_stride:\n",
    "                    input_ = tf.concat([input_, queue.pop(0)], dim=1)\n",
    "\n",
    "\n",
    "            \n",
    "            outputs[t] = self.layers_[\"output\"](input_)\n",
    "\n",
    "        outputs = outputs[-output_frames:]\n",
    "\n",
    "        outputs = tf.stack([outputs[t] for t in range(output_frames)], axis = 1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n",
      "(10000, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "image_channels = 1\n",
    "batch_size = 50\n",
    "input_shape = (batch_size, 20, 1, 64, 64)\n",
    "convttlstm = ConvTTLSTMNet(1, [3,3,3,3], [32,48,48,32])\n",
    "outputs = convttlstm.call(data, 20, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 5, 64, 64, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
