{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, AvgPool2D, Layer, Add\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"./data/mnist_test_seq.npy\"\n",
    "\n",
    "if not os.path.exists('./data'):\n",
    "    os.mkdir('./data')\n",
    "    \n",
    "# Download data\n",
    "if not os.path.exists(dataset):\n",
    "    r = requests.get(\"http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\")\n",
    "    open(dataset, 'wb').write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "def plot_sequence_images(image_array):\n",
    "    dpi = 72.0\n",
    "    xpixels, ypixels = image_array[0].shape[:2]\n",
    "    fig = plt.figure(figsize=(ypixels/dpi, xpixels/dpi), dpi=dpi)\n",
    "    im = plt.figimage(image_array[0])\n",
    "\n",
    "    def animate(i):\n",
    "        if image_array[i].shape[-1] == 1:\n",
    "            image = image_array[i][:,:,0]\n",
    "        else:\n",
    "            image = image_array[i]\n",
    "        im.set_array(image)\n",
    "        return (im,)\n",
    "\n",
    "    anim = animation.FuncAnimation(fig, animate, frames=len(image_array), interval=33, repeat_delay=1, repeat=True)\n",
    "    display(HTML(anim.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "\n",
    "assert os.path.exists(dataset), \"ASSERT ERROR: The file does not exist.\"\n",
    "data = np.float32(np.load(dataset) / 255.0)\n",
    "data_samples = data.shape[0]\n",
    "\n",
    "data_frames  = data.shape[1]\n",
    "data = np.swapaxes(data, 0, 1)\n",
    "data = np.expand_dims(data, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"64\" height=\"64\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAL0m1kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MiBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAFyZYiE\n",
       "AH/+wn/mWTOXlV/zef7P+QABw0kPxyuAGejYRJHuXl11aNdHNzT2OKlGNPA2LPpusVw3FWiaQ9q7\n",
       "y8oKAHUCcdpQPGGbFYn/yvuGDwzWn0i2bw4sjlZIJmsXlrm5g4Smfd9qzF6zN0h1ZiDJy/GqKCvf\n",
       "XkEhTL4lP/1d9D8BXeko7lH+NC2lYlCOij29MyQ1ZXFk/vRLNyGfeU6X00t8+tw8lRRkkAgosTMn\n",
       "cH5FhKTuAp8zq6dVR68cOrwKG0++x/HvaoNVbzK6zCvsMB0ZB1MZrzD/CdeNh8kH7t2ufgYyHoXm\n",
       "2lLu66xkE7WYcRClztFKmjqRPqDuFQx4GF1gCf5N7gEccBbkDfAxTGRWvp8eBUehQVs2k4j/tMqs\n",
       "QZlt28UUcPW5AJiaHO+GLxaGMY1ZyFySworE8eocz6YKOg4z16I8jELK2kcrKy1QbNmnNSgwalSH\n",
       "RjTxNM1wJNFwfoPGyI8s4UqmBSMm/GTHOQAAAY1BmiRsQz+MhqyuxbDc50d8n9/LFLxaAESG4dWH\n",
       "XTpYDU9uCdAEf3NJEppbLNI1K7JMHJtzZNAcZ9/kTud0+Bo0bYXlP3qiTybKfzrakkxxVCDXfhQd\n",
       "6yfitkyFDziqQH1iUsTIVi4m7CT+1HdcqzMCy9z2MfFmtlLDjS670yLPDDCAsfpaJhx++5uyNzaf\n",
       "wld2d8B1qdW5St/stva0wl1o5iv3LwBof1+JhQUWh+2ksmGWJCLeBhp/GB3E2cFvQpoeIQdSrBRJ\n",
       "EgvSD8lTykZ/EIMIMZgrVn0yL7mmC0FMHZQo7Gg0iKNb8LriL6pIxlXnenCbyioeLWkjeTwCNZRU\n",
       "mZ2vqeAU/1LvMhi64fhyixZKQ2Yu/98xqlHMztnkpeCmYHMymauCxkjlbmpJeMkyZbmHvrQzHAFc\n",
       "700V50opeA6m1+VINoUHtMnvG3H4tW7d2ayWWzVTpnhLB8XI4TAV8lVSQTe+S81fwW1Gy2SMU82E\n",
       "Kvw6EmCH713TJYpwonvByHFi38JBjL04j8u4AAAAVkGeQniE//dfB7wAj0wAaS35BFxySDzb9vUI\n",
       "8W+pzy+PEReqHlvC6M4j/qyKRVdioRlCRmoiFcC83Flzc6nxmuRSxZWJKsTCVZp6sGYRS89IQ9AN\n",
       "GP+5AAAATQGeYXRF/8iUG65J1AGdYhBEaARd1NojumqtE+e73Y07kz7AyHSlBbIyOA50Vk40Ri+5\n",
       "nNkNaXlxH/qriHYESWv7CQyQhLbbrbCSdyqcAAAALAGeY2pF//qw/owGRJZSiZQQ+Ar7oZPMACKE\n",
       "vGT0Wvd0h4iZmAHJstEugeT7AAAAsEGaZUmoQWiZTAh3/5BxhA22WEDABnzRFhCRsA++0qa2ihDt\n",
       "C0DN1mGUYPE3JVLi7GQ4mduHMKbT7ms1MigP2+rmCWB1B3n8V9YvAKcIDKdauiGKw90A4iE/VPRo\n",
       "5rPnD69ME+aysX+07oBw9jjmC9z647fzmms2wKFrU8mYEyUfyWsoC0Tix1idZoFyQvsNiOseZ8+Y\n",
       "JRt57SINv4v5fvNCvnBa0ZmbZ0Y/k63wPe+BAAAAZ0GaiEnhClJlMCFfiTzqfq4Sd9NQSDOXE08g\n",
       "h0x3h7XGPCq/M6WvILKsp5nA/vLDXBiNE2ii67cS1wOt1UXpmAOCivo94gRArh2p/hvQ/8cKtY5K\n",
       "1w1qFewYbo6QcGlXFsJOv/aL3uEAAAA6QZ6mRTRMI/+phxjg0MfR2af/SFchYASXzdVZXkRlKUba\n",
       "i7YS4kjN9I0FgOjtCl4h1JABhdQR9Y5lzQAAACsBnsdqRf950Vi5TEWiuAGj0LL01F50zUcr+ubN\n",
       "kjuJR2fJLlz+L2s4On1MAAAARkGayUmoQWiZTAhf//UPpmnVgBWJvinI+xh7nvCaUiaYVkLCRB/G\n",
       "Ck0NGeG8aEFSxBnNxof38t0ntLjxycPMnZKMYXyhecAAAABYQZrrSeEKUmUwURLG/8EtjOB9PHy4\n",
       "ldvQuXm9zs/eYlnuY3H1SpW7Qq0/ryuejEc/2oU/CgOrlJvpMCYpfm5AP+eGZ7rUGgZd1W2CdmDH\n",
       "/NMhARm3/Mu7bwAAAEABnwpqRf+4O/dR0HtAE7i1WQcwS0nbAoXfCdp68DYzkCKax4rpDHBhQr2S\n",
       "9ZFKYj3UvR2IvfPJoH7vUfMdwV1gAAAAQ0GbDEnhDomUwIv/1DYnC+wCfHbHssZQMQ/5XwyWuXQA\n",
       "zQzdhg2gGIyEo+qUQjThFEtLh91fjABMnvntA/0CqbDeYv4AAACOQZstSeEPJlMCL//REjG8gvYA\n",
       "j0qO7cYQaRiMssyRBKzcr8ThxQ2LpZy0NnuL+B5UoRkKWMLRZFnQqwDNGJv5Zm1s5mtwRNBzbU91\n",
       "Ep9Z8Seq79lWTgHnivYcdPiWzNtdD1U6J8sjknl0XcURvSqgzlRvE85lpgoyg/222ff8VTplnD+o\n",
       "/DZNfttW0Gm6fQAAAIRBm05J4Q8mUwIv/8inDb+5idgQmmWcAVTTjnhkb4lhgVs8ZtsorffUGrmz\n",
       "tyHAin9OfFD0Dbp4bnEIQQjuXRUIYBGuIDTmbLcTFHFkAxn4q/3CrASL6yzGiP9fCYJYhav4fQll\n",
       "InmlNWJbjvsTGuznipsOlNxGv6gg1Tmr74a25VJVP5EAAABZQZtvSeEPJlMCL//XOsdvLPYARquP\n",
       "VyREcgbDdOGeplryalfXLF2uxh8zSKmShqeV06sQEsdbSDExfOwxF9d84wyCKtIQJYTynncIWe9Z\n",
       "VIRBFRgU8SxKDUEAAABwQZuQSeEPJlMCH//qIK+1U9usfK7/uaFBs70frtT+A9ugB0rqMcsOXnr2\n",
       "36zl0yvS6NgDPpJMQPzpDqQJsf/njMBJmVHW0QJ6mHI7pL+ESzzWDGLZn1CSz3PvU3Rx8oU4QKpQ\n",
       "BvX/EeRztKX6rz0/wAAAAClBm7NJ4Q8mUwIn/88/2Xbfn1VylAQ/hq+tYj1+rYAny9hFNTPlK+Lr\n",
       "VAAAADJBn9FFETwh//ciTQ5Uq3C+9P2oT3dgBAKsDArVxtQfon+uIbtOdqdfsthe8SJlg5o+VQAA\n",
       "ACcBn/JqS//zO6DqeQs9SM8fn3FAHN77KJfYb8fr40G1v1l/IUX06/QAAAPsbW9vdgAAAGxtdmhk\n",
       "AAAAAAAAAAAAAAAAAAAD6AAAApQAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAA\n",
       "AAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAAxZ0cmFrAAAAXHRr\n",
       "aGQAAAADAAAAAAAAAAAAAAABAAAAAAAAApQAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAA\n",
       "AAABAAAAAAAAAAAAAAAAAABAAAAAAEAAAABAAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAAKU\n",
       "AAAEIAABAAAAAAKObWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAA+gAAAKUBVxAAAAAAALWhkbHIA\n",
       "AAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAACOW1pbmYAAAAUdm1oZAAAAAEA\n",
       "AAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAflzdGJsAAAAsXN0\n",
       "c2QAAAAAAAAAAQAAAKFhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAEAAQABIAAAASAAAAAAA\n",
       "AAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAL2F2Y0MBZAAK/+EAFmdk\n",
       "AAqs2UQmhAAAAwCEAAAfQDxIllgBAAZo6+PLIsAAAAAcdXVpZGtoQPJfJE/FujmlG88DI/MAAAAA\n",
       "AAAAGHN0dHMAAAAAAAAAAQAAABQAAAIQAAAAFHN0c3MAAAAAAAAAAQAAAAEAAACAY3R0cwAAAAAA\n",
       "AAAOAAAAAQAABCAAAAABAAAKUAAAAAEAAAQgAAAAAQAAAAAAAAABAAACEAAAAAEAAAQgAAAAAQAA\n",
       "CEAAAAACAAACEAAAAAEAAAQgAAAAAQAABjAAAAABAAACEAAAAAUAAAQgAAAAAQAACEAAAAACAAAC\n",
       "EAAAABxzdHNjAAAAAAAAAAEAAAABAAAAFAAAAAEAAABkc3RzegAAAAAAAAAAAAAAFAAABCgAAAGR\n",
       "AAAAWgAAAFEAAAAwAAAAtAAAAGsAAAA+AAAALwAAAEoAAABcAAAARAAAAEcAAACSAAAAiAAAAF0A\n",
       "AAB0AAAALQAAADYAAAArAAAAFHN0Y28AAAAAAAAAAQAAACwAAABidWR0YQAAAFptZXRhAAAAAAAA\n",
       "ACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAA\n",
       "AAEAAAAATGF2ZjU4LjI5LjEwMA==\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 64x64 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sequence_images(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 20, 64, 64, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data_samples, data_frames)\n",
    "display(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTTLSTMLayer(Layer):\n",
    "    def __init__(self, input_channels, hidden_channels,\n",
    "                      order=3, steps=3, ranks=8,\n",
    "                      kernel_size=(5, 5), bias=True):\n",
    "        super(ConvTTLSTMLayer, self).__init__()\n",
    "        \n",
    "        ## Input/output interfaces\n",
    "        self.input_channels  = input_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        \n",
    "        # Number of hidden states taken\n",
    "        self.steps = steps\n",
    "        # Number of G matrices\n",
    "        self.order = order\n",
    "        # How many hiddent step by group to be preprocessed together\n",
    "        self.lags = steps - order + 1\n",
    "        \n",
    "        ## Convolutional operations\n",
    "        padding     = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        \n",
    "        # Change to 3D ? Same effecct but different optimisations\n",
    "        preprocessing_Conv2D = lambda out_channels:  Conv2D(out_channels,\n",
    "                                                            kernel_size=kernel_size,\n",
    "                                                            padding=padding + (0,),\n",
    "                                                            use_bias=bias)\n",
    "    \n",
    "        tt_Conv2D = lambda out_channels:  Conv2D(out_channels,\n",
    "                                                  kernel_size=kernel_size,\n",
    "                                                  padding=padding,\n",
    "                                                  use_bias=bias)\n",
    "\n",
    "        self.layers_preprocess = []\n",
    "        self.layers_conv2d = []\n",
    "        \n",
    "        for l in range(order):\n",
    "            self.layers_preprocess.append(preprocessing_Conv2D( \n",
    "                out_channels = ranks if l < order - 1 else 4 * hidden_channels))\n",
    "            \n",
    "            self.layers_conv2d.append(tt_Conv2D(out_channels = ranks))\n",
    "        \n",
    "        def initialize(self, inputs):\n",
    "            '''\n",
    "            Initialize the hidden cell states H\n",
    "            '''\n",
    "            \n",
    "            batch_size, input_channels, height, width = inputs.size()\n",
    "            \n",
    "            self.hidden_states = [tf.zeros([batch_size, \n",
    "                height, width, self.hidden_channels])] * self.steps\n",
    "            self.hidden_state_index = 0\n",
    "            self.cell_states = tf.zeros([batch_size,\n",
    "                height, width, self.hidden_channels])\n",
    "        \n",
    "        def call(self, inputs, first_step = False):\n",
    "            '''\n",
    "            Call the model\n",
    "            '''\n",
    "            if first_step:\n",
    "                self.initialize(inputs)\n",
    "                first_step = False\n",
    "            \n",
    "            ## Preprocessing + Convolutional tensor-train module\n",
    "            ## Algorithm 2\n",
    "            for i in range(self.order):\n",
    "                input_pointer = self.hidden_state_index if not i else (input_pointer + 1) % self.steps\n",
    "                \n",
    "                # Start hidden states input at pointer but wrap around\n",
    "                input_states = self.hidden_states[input_pointer:] + self.hidden_states[:input_pointer]\n",
    "                \n",
    "                # Take one group of Hidden States\n",
    "                input_states = input_states[:self.lags]\n",
    "                \n",
    "                input_states = tf.stack(input_states, dim=-1)\n",
    "                input_states = self.layers_preprocess[l](input_states)\n",
    "                \n",
    "                if i == 0:\n",
    "                    temp_states = input_states\n",
    "                else: # if i > 0\n",
    "                    temp_states = input_states + self.layers_conv2d[l - 1](temp_states)\n",
    "                \n",
    "            ## Standard convolutional-LSTM module\n",
    "            concat_conv = self.layers_conv2d(tf.concat([inputs, temps_states], dim=-1))\n",
    "            cc_i, cc_f, cc_o, cc_g = tf.split(concat_conv, self.hidden_channels, dim = -1)\n",
    "            \n",
    "            \n",
    "            i = tf.math.sigmoid(cc_i)\n",
    "            f = tf.math.sigmoid(cc_f)\n",
    "            o = tf.math.sigmoid(cc_o)\n",
    "            g = tf.math.tanh(cc_g)\n",
    "            \n",
    "            self.cell_states = f * self.cell_states + i * g\n",
    "            outputs = o * torch.tanh(self.cell_states)\n",
    "            self.hidden_states[self.hidden_state_index] = outputs\n",
    "            self.hidden_pointer = (self.hidden_state_index + 1) % self.steps\n",
    "\n",
    "            return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "convttlstm = ConvTTLSTMLayer(5,3)\n",
    "convttlstm.build((None, *input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTTLSTMNet(Model):\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 layers_per_block:list, hidden_channels:list, skip_stride = None,\n",
    "                 # Params for the TTLSTM\n",
    "                 order=3, steps=3, ranks=8,\n",
    "                 kernel_size = (3,3), bias = True,\n",
    "                 output_sigmoid = False,\n",
    "                 # Calling parameters\n",
    "                 \n",
    "                ):\n",
    "        super(ConvTTLSTMNet, self).__init__()\n",
    "        \n",
    "        ## Hyperparameters\n",
    "        self.layers_per_block = layers_per_block\n",
    "        self.hidden_channels  = hidden_channels\n",
    "\n",
    "        self.num_blocks = len(layers_per_block)\n",
    "        assert self.num_blocks == len(hidden_channels), \"Invalid number of blocks.\"\n",
    "        \n",
    "        \n",
    "        self.skip_stride = (self.num_blocks + 1) if skip_stride is None else skip_stride\n",
    "\n",
    "        self.output_sigmoid = output_sigmoid\n",
    "        \n",
    "        self.layers_ = {}\n",
    "        \n",
    "        # Model Architecture\n",
    "        for b in range(self.num_blocks):\n",
    "            for l in range(layers_per_block[b]):\n",
    "                # number of input channels to the current layer\n",
    "                if l > 0:\n",
    "                    channels = hidden_channels[b]\n",
    "                elif b == 0:\n",
    "                    channels = input_channels\n",
    "                else:\n",
    "                    # First layer of a block after the first one\n",
    "                    channels = hidden_channels[b - 1]\n",
    "                \n",
    "                # We keep the layer id for skip connections\n",
    "                # FIXME ? Maybe there's something to do that with Keras ? Unsure\n",
    "                lid = \"b{}l{}\".format(b, l)\n",
    "                \n",
    "                cttlstmlayer = ConvTTLSTMLayer(\n",
    "                    input_channels = channels, hidden_channels = hidden_channels[b],\n",
    "                    order = order, steps = steps, ranks = ranks, \n",
    "                    kernel_size = kernel_size, bias = bias)\n",
    "                \n",
    "                self.layers_[lid] = cttlstmlayer\n",
    "                \n",
    "        # Last Layer\n",
    "        # nb of input\n",
    "        channels = hidden_channels[-1]\n",
    "        \n",
    "        # ???????\n",
    "        # Si il y a plus de blocks que la distance de skip, alots on ajoute Ã  l'input\n",
    "        # le skip ? FIXME ==> Essayez de comprendre\n",
    "        if self.num_blocks >= self.skip_stride:\n",
    "            channels += hidden_channels[-1-self.skip_stride]\n",
    "            \n",
    "        if self.output_sigmoid:\n",
    "            activation=\"sigmoid\"\n",
    "        else:\n",
    "            activation=None\n",
    "            \n",
    "        self.layers_[\"output\"] = Conv2D(input_channels, kernel_size=(1,1), \n",
    "                                       activation=activation, padding=\"same\", use_bias=True)\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, input_frames:int, future_frames:int, output_frames:int,\n",
    "                teacher_forcing = False, scheduled_sampling_ratio = 0):\n",
    "            # tf is teacher forcing ?\n",
    "        if teacher_forcing and scheduled_sampling_ratio > 1e-6:\n",
    "            teacher_forcing_mask = np.random.binomial(size=(inputs.size(0), future_frames - 1, 1, 1, 1), n=1, p=scheduled_sampling_ratio)\n",
    "        else:\n",
    "            teacher_forcing = False\n",
    "            \n",
    "        total_steps = input_frames + future_frames - 1\n",
    "        outputs = [None] * total_steps\n",
    "\n",
    "        for t in range(total_steps):\n",
    "            if t < input_frames: \n",
    "                input_ = inputs[:, t]\n",
    "            elif not teacher_forcing:\n",
    "                input_ = outputs[t-1]\n",
    "            else: # if t >= input_frames and teacher_forcing:\n",
    "                mask = teacher_forcing_mask[:, t - input_frames]\n",
    "                input_ = inputs[:, t] * mask + outputs[t-1] * (1 - mask)\n",
    "\n",
    "            #print(input_.shape)\n",
    "            first_step = (t == 0)\n",
    "\n",
    "            queue = []\n",
    "\n",
    "            for b in range(self.num_blocks):\n",
    "                for l in range(self.layers_per_block[b]):\n",
    "                    lid = \"b{}l{}\".format(b, l)\n",
    "                    input_ = self.layers_[lid](input_, first_step = first_step)\n",
    "\n",
    "                queue.append(input_)\n",
    "                if b >= self.skip_stride:\n",
    "                    input_ = tf.concat([input_, queue.pop(0)], dim=1)\n",
    "\n",
    "\n",
    "            \n",
    "            outputs[t] = self.layers_[\"output\"](input_)\n",
    "\n",
    "        outputs = outputs[-output_frames:]\n",
    "\n",
    "        outputs = tf.stack([outputs[t] for t in range(output_frames)], axis = 1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels = 1\n",
    "batch_size = 50\n",
    "predict_frames = 50\n",
    "input_shape = (batch_size, 20, 1, 64, 64)\n",
    "batch = data[:batch_size]\n",
    "convttlstm = ConvTTLSTMNet(1, [3,3,3,3], [32,48,48,32])\n",
    "outputs = convttlstm.call(batch, 20, predict_frames, predict_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([50, 50, 64, 64, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"64\" height=\"64\" controls autoplay loop>\n",
       "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAHGZ0eXBNNFYgAAACAGlzb21pc28yYXZjMQAAAAhmcmVlAAAIzW1kYXQAAAKuBgX//6rcRem9\n",
       "5tlIt5Ys2CDZI+7veDI2NCAtIGNvcmUgMTU1IHIyOTE3IDBhODRkOTggLSBILjI2NC9NUEVHLTQg\n",
       "QVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE4IC0gaHR0cDovL3d3dy52aWRlb2xhbi5vcmcv\n",
       "eDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5c2U9\n",
       "MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRfcmVm\n",
       "PTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRlYWR6\n",
       "b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MiBsb29r\n",
       "YWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFj\n",
       "ZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJh\n",
       "bWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdl\n",
       "aWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVz\n",
       "aD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBx\n",
       "cG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAG6ZYiE\n",
       "ACP//sdv5lk8KIQGSV2UeTLC1updVsaAPAfZ0cHbESeM6MApkNfUZ7bHDSs7nCnihV8updNBhWYK\n",
       "2DCJiTjGGPRHfARRkQfEhPbNxCAI+nLx7QeT212LMkdJKs7x5ux1aPnxi3llcryfgUAe9l+ka8cP\n",
       "idMLWTf98YLPyjXIHEfr+MDTDn5ljtdBQzkvwr6Pzn8KzPP26hbg6cTu18CNxr0gpwzpVM3SLULu\n",
       "RL5OmjxAC/jOARkAg9xxK/UtYLrYtVyClxUwNR2b3M6z1tiH9MW/LShRXiI89+twZRA/ueBeHYd2\n",
       "csvYZ7cs/SwfvYzxC/MW4SlDwy/8fGeJwNCHdd6BrcOU4kT3ZyXL13mgRVhWnEbmKOb0Bkyvxu6d\n",
       "LnTgrhWq82rFBDIJMILC8BevIeXBHsQypu8FjcqcvI1h3SuM5oYgCbqvl4JFnsLBGb1Xb5NP2HSg\n",
       "4I+d0lkeaXi8AIfflthS+YfS+yXd8cQirxP2xS1Vy8poCdIOuMnRa/3HLJ60j3/wniMJUhACUP9p\n",
       "osT7LKPOaosPWYqV9kh9sr55e4VKRjuZN59L6qcSD1byGdotAADEQQAAAH5BmiJhBoCOBNGAPoDs\n",
       "A/0I//wK8CAk31zoFQySnMVxTuuMJZc5mB7q+Kdr5UibjT9Viu+mtVcVkFvbGC3oFgEm7/zVN4IF\n",
       "OW0W+RLiMeEaHZjvkd+INw5D9Cpqh1L1WEAcSff5IKbUZCCnKheucDTV9UkGvCozn1opCBGO++AA\n",
       "AAAKAZ5BeRP/TAnbHwAAABxBmkNJ4QhDIcRA1DoGYBdAN4FEDUMAhH/94daAAAAAPUGaZ0vhCEPI\n",
       "IPARQJoCAgyAW0BFAkAI/3PuWISp8tNwBfooAw4BV8xNNZ1f/fXN/XoS5Pmyc0EBdKKKuE0AAAAL\n",
       "QZ6FRRE8b0VSwM8AAAALAZ6kdEX/Tf0KG8EAAAAMAZ6makX/Q8F9k4VlAAAALUGaqEuoQhBaIINA\n",
       "aw6BAgyAhQGsMAIR//33gIAJB4n4rkMs09a4tARxtrAn8AAAACBBmslL4QhClIIwGsOQGsMAIR/7\n",
       "88UAFkCbPwodfes7gAAAACFBmupL4QhDohcNBBDQ4AhP//xLIGgTHXkRhFcGW0Yxgt0AAAAuQZsL\n",
       "S+EIQ8gjAZwQQGcOAIT//EsXgCJhmqzsG4RqOF9WU5EfHM0lBb9MlmDd8AAAACJBmy9L4QhDyGPD\n",
       "QMoCAguAYUNAwAIT//xLIGgjRraBNJiLAAAAC0GfTUURPG8gyI5lAAAADAGfbHRF/0Ncl0O+gQAA\n",
       "AAwBn25qRf9Dv9f0xMEAAAAkQZtzS6hCEFoh8FwNkFwNACFf/NffSfiPF5tLao1peWOn99r4AAAA\n",
       "CUGfkUURLG8ZEAAAAAgBn7B0Rf8dUQAAAA0Bn7JqRf94/66mCaOwAAAAG0Gbt0uoQhBbIfBcDZBc\n",
       "DQAhX/4+3M1vNWJXXgAAABJBn9VFFSxvcFw1OUSXD37HroEAAAANAZ/0dEX/eDkvf2mTYAAAAAgB\n",
       "n/ZqRf8dUQAAABtBm/tLqEIQWyeBUYFIAhX//WYn4fa2nlwupuEAAAATQZ4ZRRUsb3GzqUEB9OF9\n",
       "D9ayOAAAABEBnjh0Rf94OS6L6qNaVvyTHQAAAAgBnjpqRf8dUAAAABBBmj9JqEFsmUwIV//+OI3B\n",
       "AAAACUGeXUUVLG8ZEQAAAAgBnnx0Rf8dUAAAAAgBnn5qRf8dUAAAABBBmmNJqEFsmUwIT//98a2B\n",
       "AAAACUGegUUVLG8ZEAAAAAgBnqB0Rf8dUQAAAAgBnqJqRf8dUAAAABBBmqdJqEFsmUwIT//98a2B\n",
       "AAAACUGexUUVLG8ZEQAAAAgBnuR0Rf8dUQAAAAgBnuZqRf8dUQAAABBBmutJqEFsmUwIT//98a2A\n",
       "AAAACUGfCUUVLG8ZEAAAAAgBnyh0Rf8dUQAAAAgBnypqRf8dUAAAAA5Bmy9JqEFsmUwI//yGUgAA\n",
       "AAlBn01FFSxvGREAAAAIAZ9sdEX/HVEAAAAIAZ9uakX/HVEAAAAPQZtxSahBbJlMFExf+lu2AAAA\n",
       "CAGfkGpF/x1QAAAFbG1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAAZyAAEAAAEAAAAAAAAA\n",
       "AAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAAAAAAAAAAAIAAASWdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAAZyAAAAAAAA\n",
       "AAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAABAAAAAQAAAAAAA\n",
       "JGVkdHMAAAAcZWxzdAAAAAAAAAABAAAGcgAABCAAAQAAAAAEDm1kaWEAAAAgbWRoZAAAAAAAAAAA\n",
       "AAAAAAAAPoAAAGcgVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5k\n",
       "bGVyAAAAA7ltaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEA\n",
       "AAAMdXJsIAAAAAEAAAN5c3RibAAAALFzdHNkAAAAAAAAAAEAAAChYXZjMQAAAAAAAAABAAAAAAAA\n",
       "AAAAAAAAAAAAAABAAEAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
       "AAAAABj//wAAAC9hdmNDAWQACv/hABZnZAAKrNlEJoQAAAMAhAAAH0A8SJZYAQAGaOvjyyLAAAAA\n",
       "HHV1aWRraEDyXyRPxbo5pRvPAyPzAAAAAAAAABhzdHRzAAAAAAAAAAEAAAAyAAACEAAAABRzdHNz\n",
       "AAAAAAAAAAEAAAABAAABiGN0dHMAAAAAAAAALwAAAAEAAAQgAAAAAQAABjAAAAABAAACEAAAAAEA\n",
       "AAQgAAAAAQAAClAAAAABAAAEIAAAAAEAAAAAAAAAAQAAAhAAAAAEAAAEIAAAAAEAAApQAAAAAQAA\n",
       "BCAAAAABAAAAAAAAAAEAAAIQAAAAAQAAClAAAAABAAAEIAAAAAEAAAAAAAAAAQAAAhAAAAABAAAK\n",
       "UAAAAAEAAAQgAAAAAQAAAAAAAAABAAACEAAAAAEAAApQAAAAAQAABCAAAAABAAAAAAAAAAEAAAIQ\n",
       "AAAAAQAAClAAAAABAAAEIAAAAAEAAAAAAAAAAQAAAhAAAAABAAAKUAAAAAEAAAQgAAAAAQAAAAAA\n",
       "AAABAAACEAAAAAEAAApQAAAAAQAABCAAAAABAAAAAAAAAAEAAAIQAAAAAQAAClAAAAABAAAEIAAA\n",
       "AAEAAAAAAAAAAQAAAhAAAAABAAAKUAAAAAEAAAQgAAAAAQAAAAAAAAABAAACEAAAAAEAAAYwAAAA\n",
       "AQAAAhAAAAAcc3RzYwAAAAAAAAABAAAAAQAAADIAAAABAAAA3HN0c3oAAAAAAAAAAAAAADIAAARw\n",
       "AAAAggAAAA4AAAAgAAAAQQAAAA8AAAAPAAAAEAAAADEAAAAkAAAAJQAAADIAAAAmAAAADwAAABAA\n",
       "AAAQAAAAKAAAAA0AAAAMAAAAEQAAAB8AAAAWAAAAEQAAAAwAAAAfAAAAFwAAABUAAAAMAAAAFAAA\n",
       "AA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAA\n",
       "DAAAABIAAAANAAAADAAAAAwAAAATAAAADAAAABRzdGNvAAAAAAAAAAEAAAAsAAAAYnVkdGEAAABa\n",
       "bWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9v\n",
       "AAAAHWRhdGEAAAABAAAAAExhdmY1OC4yOS4xMDA=\n",
       "\">\n",
       "  Your browser does not support the video tag.\n",
       "</video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 64x64 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sequence_images(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters and hyper-parameters\n",
    "num_training_iterations = 2000 \n",
    "batch_size = 10\n",
    "learning_rate = 1e-3 \n",
    "seq_len = 5\n",
    "\n",
    "# Checkpoint location: \n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and Loss function \n",
    "# Loss is based on the paper\n",
    "\n",
    "def compute_loss(y_pred, y_true):\n",
    "    loss = tf.keras.losses.MSE(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data[:batch_size]\n",
    "convttlstm = ConvTTLSTMNet(1, [3,3,3,3], [32,48,48,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train/test/validate set\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5250, 5, 64, 64, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5250, 5, 64, 64, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a random batch\n",
    "\n",
    "def make_batch(data, seq_len = 5, batch_size=350):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    random_indexes = np.random.choice(data.shape[0], batch_size)\n",
    "    for j in random_indexes:\n",
    "        inputs += [data[j, i:i + seq_len] for i in range(data.shape[1] - seq_len)]\n",
    "        outputs += [data[j, i:i + seq_len] for i in range(1, data.shape[1] - seq_len + 1)]\n",
    "        \n",
    "    inputs = np.array(inputs)\n",
    "    outputs = np.array(outputs)    \n",
    "    \n",
    "    return inputs, outputs\n",
    "\n",
    "batch_input, batch_output = make_batch(data)\n",
    "display(batch_input.shape, batch_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2000 [00:16<4:37:13,  8.32s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-065530f4f8d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_training_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmake_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        y_pred = convttlstm(x, input_frames=seq_len, future_frames=1, output_frames=seq_len)\n",
    "        loss = compute_loss(y, y_pred)\n",
    "        grads = tape.gradient(loss, convttlstm.trainable_variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(grads, convttlstm.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "history = []\n",
    "\n",
    "for iter in tqdm(range(num_training_iterations)):\n",
    "    x_batch, y_batch =  make_batch(data, seq_len)\n",
    "    loss = train_step(x_batch, y_batch)\n",
    "\n",
    "    history.append(loss.numpy().mean())\n",
    "    plt.plot(history)\n",
    "\n",
    "    if iter % 100 == 0:\n",
    "        convttlstm.save_weights(checkpoint_prefix)\n",
    "    \n",
    "convttlstm.save_weights(checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
